{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "from picamera import PiCamera\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import imutils\n",
    "import pickle\n",
    "import os\n",
    "from googleapiclient.discovery import build\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request\n",
    "from googleapiclient.http import MediaFileUpload\n",
    "\n",
    "gdfolder = '1crBqym6aiqByFbqcQn0pJkt2YRWDbVz7'\n",
    "num_pictures = 10\n",
    "\n",
    "#######################################################\n",
    "# GDrive authorization\n",
    "#######################################################\n",
    "creds = []\n",
    "SCOPES = ['https://www.googleapis.com/auth/drive.file']\n",
    "if os.path.exists('token.pickle'):\n",
    "    with open('token.pickle', 'rb') as token:\n",
    "        creds = pickle.load(token)\n",
    "\n",
    "if not creds or not creds.valid:\n",
    "    if creds and creds.expired and creds.refresh_token:\n",
    "        creds.refresh(Request())\n",
    "    else:\n",
    "        flow = InstalledAppFlow.from_client_secrets_file('credentials.json', SCOPES)\n",
    "        creds = flow.run_local_server(port=0)\n",
    "    \n",
    "    with open('token.pickle', 'wb') as token:\n",
    "        pickle.dump(creds, token)\n",
    "\n",
    "drive = build('drive', 'v3', credentials=creds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "# motion file setup\n",
    "######################################################\n",
    "# grab list of files that already exist\n",
    "results = drive.files().list(fields=\"files(id, name)\", q=\"'1crBqym6aiqByFbqcQn0pJkt2YRWDbVz7' in parents\", orderBy='name').execute()['files']\n",
    "gfiles = [results[ii]['id'] for ii in range(len(results)) if results[ii]['name'].startswith('motion')]\n",
    "\n",
    "# make new placeholder files if necessary\n",
    "for ii in range(len(gfiles), num_pictures):\n",
    "    rc = cv2.imwrite('motion.jpg', (np.random.rand(200,300,3)*255).astype(int))\n",
    "    media = MediaFileUpload('motion.jpg', mimetype='image/jpg')\n",
    "    gfile = drive.files().create(body={'name': 'motion_%s.jpg' % str(\"{0:0=4d}\".format(ii)), 'parents':[gdfolder]}, media_body=media, fields='id').execute()\n",
    "    gfiles += [gfile]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "# configuration setup\n",
    "##########################################\n",
    "box = (190, 1280, 600, 775)\n",
    "tdelay = 0.5  # seconds\n",
    "\n",
    "# calibration\n",
    "# need to measure and calibrate\n",
    "# wag is 400 pixels = 50 ft\n",
    "pixels_per_foot = 400.0/30.0\n",
    "pixels_per_mile = pixels_per_foot * 5280.0\n",
    "\n",
    "# debug\n",
    "debug = True\n",
    "\n",
    "snapshot1 = np.empty((1024, 1280, 3), dtype=np.uint8)\n",
    "snapshot2 = np.empty((1024, 1280, 3), dtype=np.uint8)\n",
    "gg = 0\n",
    "\n",
    "#fig, ax = plt.subplots(figsize=(14, 14))\n",
    "#ax.imshow(background)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "# grab camera hardware and monitor\n",
    "#####################################################\n",
    "with PiCamera(resolution=(1280, 1024)) as camera:\n",
    "    #camera.zoom = (box[0]/1280, box[2]/1024, box[1]/1280, box[3]/1024)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        while True:  #for ii in range(num_pictures):\n",
    "            \n",
    "            # take two pictures separated in time\n",
    "            camera.capture(snapshot1, format='bgr', use_video_port=True)\n",
    "            time.sleep(tdelay)\n",
    "            camera.capture(snapshot2, format='bgr', use_video_port=True)\n",
    "            \n",
    "            start = time.time()\n",
    "            \n",
    "            cutout1 = np.array(snapshot1[box[2]:box[3], box[0]:box[1]])\n",
    "            cutout2 = np.array(snapshot2[box[2]:box[3], box[0]:box[1]])\n",
    "            \n",
    "            frame1 = cv2.cvtColor(cutout1, cv2.COLOR_BGR2GRAY)\n",
    "            frame1 = cv2.GaussianBlur(frame1, (31, 31), 0)\n",
    "            frame2 = cv2.cvtColor(cutout2, cv2.COLOR_BGR2GRAY)\n",
    "            frame2 = cv2.GaussianBlur(frame2, (31, 31), 0)\n",
    "            \n",
    "            # compute the difference between the current frame and running average\n",
    "            frameDelta = cv2.absdiff(frame1, frame2)\n",
    "            \n",
    "            # threshold the delta image, dilate the thresholded image to fill in holes,\n",
    "            # then find contours on thresholded image\n",
    "            thresh = cv2.threshold(frameDelta, 30, 255, cv2.THRESH_BINARY)[1]\n",
    "            thresh = cv2.dilate(thresh, None, iterations=5)\n",
    "            cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            cnts = imutils.grab_contours(cnts)\n",
    "            \n",
    "            # look for large contour areas\n",
    "            cnts = [cc for cc in cnts if cv2.contourArea(cc) > 1000]\n",
    "             \n",
    "            # we are looking for motion from point A to point B, this should be exactly 2 changes\n",
    "            if len(cnts) == 2:\n",
    "                cc = cnts[0]\n",
    "                two_frame = cv2.addWeighted(cutout1, 0.5, cutout2, 0.5, 0.0)\n",
    "                \n",
    "                # compute the bounding box for the contour, draw it on the frame, and update the text\n",
    "                (xx, yy, ww, hh) = cv2.boundingRect(cnts[0])\n",
    "                center1 = np.array([xx + ww//2, yy + hh//2])\n",
    "                rc = cv2.rectangle(two_frame, (xx, yy), (xx + ww, yy + hh), (0, 255, 0), 2)\n",
    "                \n",
    "                (xx, yy, ww, hh) = cv2.boundingRect(cnts[1])\n",
    "                center2 = np.array([xx + ww//2, yy + hh//2])\n",
    "                rc = cv2.rectangle(two_frame, (xx, yy), (xx + ww, yy + hh), (0, 255, 0), 2)\n",
    "                \n",
    "                # convert pixel distance to real world distance\n",
    "                distance = np.abs(center1[0] - center2[0]) # in pixels\n",
    "                distance = distance / pixels_per_mile     # in miles\n",
    "                speed = distance / (tdelay/3600)           # in miles per hour\n",
    "                \n",
    "                imtxt = datetime.now().strftime('%Y-%m-%d %H:%M:%S') + '  ' + 'speed estimate = {:1.1f} mph'.format(speed)\n",
    "                print('motion detected in image ' + str(gg) + '...' + imtxt, end='\\r')\n",
    "                \n",
    "                # skip slow moving objects or single detections\n",
    "                if (not debug) and (speed < 10.0): continue\n",
    "                \n",
    "                # blend the snapshots and add space for text annotation\n",
    "                if debug:\n",
    "                    print('')\n",
    "                    print(time.time() - start)\n",
    "                    two_frame = np.concatenate((np.tile(frameDelta[...,None],3), np.tile(thresh[...,None],3), two_frame, np.zeros((80,cutout1.shape[1],3), dtype=int)+255), axis=0)\n",
    "                else:\n",
    "                    two_frame = np.concatenate((cutout1, np.zeros((10,cutout1.shape[1],3), dtype=int)+255, cutout2, np.zeros((80,cutout1.shape[1],3), dtype=int)+255), axis=0)\n",
    "                \n",
    "                cv2.putText(two_frame, imtxt, (10,two_frame.shape[0]-30), cv2.FONT_HERSHEY_DUPLEX, 1, 0)                \n",
    "                rc = cv2.imwrite('pictures/motion' + str(gg) + '.jpg', two_frame)               \n",
    "                media = MediaFileUpload('pictures/motion' + str(gg) + '.jpg', mimetype='image/jpg')\n",
    "                gfile = drive.files().update(fileId=gfiles[gg], media_body=media).execute()\n",
    "                gg = (gg + 1) % num_pictures\n",
    "                \n",
    "    except KeyboardInterrupt:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 14))\n",
    "ax.imshow(two_frame)\n",
    "print(np.min(two_frame), np.max(two_frame), np.mean(two_frame))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "from picamera import PiCamera\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import imutils\n",
    "import pickle\n",
    "import os\n",
    "from googleapiclient.discovery import build\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request\n",
    "from googleapiclient.http import MediaFileUpload\n",
    "\n",
    "gdfolder = '1crBqym6aiqByFbqcQn0pJkt2YRWDbVz7'\n",
    "num_pictures = 2\n",
    "\n",
    "#######################################################\n",
    "# GDrive authorization\n",
    "#######################################################\n",
    "creds = []\n",
    "SCOPES = ['https://www.googleapis.com/auth/drive.file']\n",
    "if os.path.exists('token.pickle'):\n",
    "    with open('token.pickle', 'rb') as token:\n",
    "        creds = pickle.load(token)\n",
    "\n",
    "if not creds or not creds.valid:\n",
    "    if creds and creds.expired and creds.refresh_token:\n",
    "        creds.refresh(Request())\n",
    "    else:\n",
    "        flow = InstalledAppFlow.from_client_secrets_file('credentials.json', SCOPES)\n",
    "        creds = flow.run_local_server(port=0)\n",
    "    \n",
    "    with open('token.pickle', 'wb') as token:\n",
    "        pickle.dump(creds, token)\n",
    "\n",
    "drive = build('drive', 'v3', credentials=creds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "# twitter setup\n",
    "######################################################\n",
    "#import tweepy\n",
    "\n",
    "#with open('twitter.txt', 'r') as fid:\n",
    "#    authdata = fid.read()\n",
    "#    consumer_key, consumer_secret = authdata.split('\\n')[:2]\n",
    "#    key, secret = authdata.split('\\n')[-2:]\n",
    "\n",
    "#auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "#auth.set_access_token(key, secret)\n",
    "#api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "# motion file setup\n",
    "######################################################\n",
    "# grab list of files that already exist\n",
    "results = drive.files().list(fields=\"files(id, name)\", q=\"'1crBqym6aiqByFbqcQn0pJkt2YRWDbVz7' in parents\", orderBy='name').execute()['files']\n",
    "gfiles = [results[ii]['id'] for ii in range(len(results)) if results[ii]['name'].startswith('motion')]\n",
    "\n",
    "# make new placeholder files if necessary\n",
    "for ii in range(len(gfiles), num_pictures):\n",
    "    rc = cv2.imwrite('motion.jpg', (np.random.rand(200,300,3)*255).astype(int))\n",
    "    media = MediaFileUpload('motion.jpg', mimetype='image/jpg')\n",
    "    gfile = drive.files().create(body={'name': 'motion_%s.jpg' % str(\"{0:0=4d}\".format(ii)), 'parents':[gdfolder]}, media_body=media, fields='id').execute()\n",
    "    gfiles += [gfile]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "# configuration setup\n",
    "##########################################\n",
    "box = (190, 1280, 600, 775)\n",
    "tdelay = 0.5  # seconds\n",
    "\n",
    "# calibration\n",
    "# need to measure and calibrate\n",
    "# wag is 400 pixels = 50 ft\n",
    "pixels_per_foot = 400.0/40.0\n",
    "pixels_per_mile = pixels_per_foot * 5280.0\n",
    "depth_adjust = 0.2  # %, cars going left to right are closer\n",
    "\n",
    "# debug\n",
    "debug = False\n",
    "\n",
    "frameb = None\n",
    "prev_cutout = None\n",
    "prev_center = None\n",
    "snapshot = np.empty((1024, 1280, 3), dtype=np.uint8)\n",
    "gg = 0\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "#fig, ax = plt.subplots(figsize=(14, 14))\n",
    "#ax.imshow(background)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "motion detected in image 1...2020-11-20 17:19:18  speed estimate = 29.0 mph\r"
     ]
    }
   ],
   "source": [
    "#####################################################\n",
    "# grab camera hardware and monitor\n",
    "#####################################################\n",
    "with PiCamera(resolution=(1280, 1024)) as camera:\n",
    "    #camera.zoom = (box[0]/1280, box[2]/1024, box[1]/1280, box[3]/1024)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        while True:  #for ii in range(num_pictures):\n",
    "            \n",
    "            # take a picture\n",
    "            time.sleep(tdelay)\n",
    "            shot_time = time.time()\n",
    "            camera.capture(snapshot, format='bgr', use_video_port=True)\n",
    "            \n",
    "            cutout = np.array(snapshot[box[2]:box[3], box[0]:box[1]])\n",
    "            \n",
    "            # compute the difference between the current frame and running average\n",
    "            frame = cv2.cvtColor(cutout, cv2.COLOR_BGR2GRAY)\n",
    "            frame = cv2.GaussianBlur(frame, (31, 31), 0)\n",
    "            \n",
    "            if frameb is None: frameb = np.array(frame)\n",
    "            \n",
    "            frameDelta = cv2.absdiff(frameb, frame)\n",
    "            \n",
    "            # threshold the delta image, dilate the thresholded image to fill in holes,\n",
    "            # then find contours on thresholded image\n",
    "            thresh = cv2.threshold(frameDelta, 30, 255, cv2.THRESH_BINARY)[1]\n",
    "            thresh = cv2.dilate(thresh, None, iterations=8)\n",
    "            rawcnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            rawcnts = imutils.grab_contours(rawcnts)\n",
    "            large_areas = [cc for cc in rawcnts if cv2.contourArea(cc) > 3000]\n",
    "            \n",
    "            # look for one large motion contour area\n",
    "            if len(large_areas) == 1:\n",
    "                cc = large_areas[0]\n",
    "                \n",
    "                # compute the bounding box for the contour, draw it on the frame, and update the text\n",
    "                (xx, yy, ww, hh) = cv2.boundingRect(cc)\n",
    "                center = np.array([xx + ww//2, yy + hh//2])\n",
    "                rc = cv2.rectangle(cutout, (xx, yy), (xx + ww, yy + hh), (0, 255, 0), 2)\n",
    "            \n",
    "                # if we had a large motion contour area in the previous frame as well\n",
    "                if prev_center is not None:\n",
    "                \n",
    "                    # convert pixel distance to real world distance\n",
    "                    distance = np.abs(center[0] - prev_center[0])             # in pixels\n",
    "                    distance = distance / pixels_per_mile                     # in miles\n",
    "                    speed = distance / ((shot_time-prev_shot_time)/3600)  # in miles per hour\n",
    "                    \n",
    "                    # adjust speed for cars in near lane (left to right)\n",
    "                    if prev_center[0] < center[0]:\n",
    "                        speed = speed * (1.0 - depth_adjust)\n",
    "                \n",
    "                    imtxt = datetime.now().strftime('%Y-%m-%d %H:%M:%S') + '  ' + 'speed estimate = {:1.1f} mph'.format(speed)\n",
    "                    print('motion detected in image ' + str(gg) + '...' + imtxt, end='\\r')\n",
    "                \n",
    "                    # blend the snapshots and add space for text annotation\n",
    "                    if debug:\n",
    "                        print('')\n",
    "                        print(shot_time-prev_shot_time)\n",
    "                        two_frame = cv2.addWeighted(prev_cutout, 0.5, cutout, 0.5, 0.0)\n",
    "                        two_frame = np.concatenate((np.tile(frameDelta[...,None],3), np.tile(thresh[...,None],3), two_frame, np.zeros((80,cutout.shape[1],3), dtype=int)+255), axis=0)\n",
    "                    else:\n",
    "                        two_frame = np.concatenate((prev_cutout, np.zeros((10,cutout.shape[1],3), dtype=int)+255, cutout, np.zeros((80,cutout.shape[1],3), dtype=int)+255), axis=0)\n",
    "                \n",
    "                    # save things moving faster than people\n",
    "                    if speed > 10.0:\n",
    "                        cv2.putText(two_frame, imtxt, (10,two_frame.shape[0]-30), cv2.FONT_HERSHEY_DUPLEX, 1, 0)                \n",
    "                        fname = 'pictures/' + datetime.now().strftime('%Y-%m-%d %H:%M:%S') + '__{:1.1f}mph.jpg'.format(speed)\n",
    "                        rc = cv2.imwrite(fname, two_frame)\n",
    "                    \n",
    "                        # only upload fast moving objects\n",
    "                        if speed > 32.0:\n",
    "                            try:\n",
    "                                media = MediaFileUpload(fname, mimetype='image/jpg')\n",
    "                                gfile = drive.files().update(fileId=gfiles[gg], media_body=media).execute()\n",
    "                            except:\n",
    "                                pass\n",
    "                            gg = (gg + 1) % num_pictures\n",
    "                        \n",
    "                    elif speed < 2:  # good chance we are hung on an incorrect background\n",
    "                        frameb = np.array(frame)\n",
    "                \n",
    "                # save this motion contour area for next frame comparison \n",
    "                prev_center = center\n",
    "                prev_cutout = cutout\n",
    "            \n",
    "            # no large motion contour area\n",
    "            else:\n",
    "                prev_center = None\n",
    "                prev_cutout = None\n",
    "                frameb = np.array(frame)\n",
    "            \n",
    "            prev_shot_time = shot_time\n",
    "                \n",
    "    except KeyboardInterrupt:\n",
    "        pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

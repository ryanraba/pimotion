{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from picamera import PiCamera\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets  import RectangleSelector\n",
    "import cv2\n",
    "import imutils\n",
    "import pickle\n",
    "import os.path\n",
    "from googleapiclient.discovery import build\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request\n",
    "from googleapiclient.http import MediaFileUpload\n",
    "\n",
    "gdfolder = '1crBqym6aiqByFbqcQn0pJkt2YRWDbVz7'\n",
    "num_pictures = 50\n",
    "\n",
    "#######################################################\n",
    "# GDrive authorization\n",
    "#######################################################\n",
    "creds = []\n",
    "SCOPES = ['https://www.googleapis.com/auth/drive.file']\n",
    "if os.path.exists('token.pickle'):\n",
    "    with open('token.pickle', 'rb') as token:\n",
    "        creds = pickle.load(token)\n",
    "\n",
    "if not creds or not creds.valid:\n",
    "    if creds and creds.expired and creds.refresh_token:\n",
    "        creds.refresh(Request())\n",
    "    else:\n",
    "        flow = InstalledAppFlow.from_client_secrets_file('credentials.json', SCOPES)\n",
    "        creds = flow.run_local_server(port=0)\n",
    "    \n",
    "    with open('token.pickle', 'wb') as token:\n",
    "        pickle.dump(creds, token)\n",
    "\n",
    "drive = build('drive', 'v3', credentials=creds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "# motion file setup\n",
    "######################################################\n",
    "# grab list of files that already exist\n",
    "results = drive.files().list(fields=\"files(id, name)\", q=\"'1crBqym6aiqByFbqcQn0pJkt2YRWDbVz7' in parents\").execute()['files']\n",
    "gfiles = [results[ii]['id'] for ii in range(len(results)) if results[ii]['name'].startswith('motion')]\n",
    "\n",
    "# make new placeholder files if necessary\n",
    "for ii in range(len(gfiles), num_pictures):\n",
    "    rc = cv2.imwrite('motion.jpg', (np.random.rand(200,300,3)*255).astype(int))\n",
    "    media = MediaFileUpload('motion.jpg', mimetype='image/jpg')\n",
    "    gfile = drive.files().create(body={'name': 'motion_%s.jpg'%str(ii), 'parents':[gdfolder]}, media_body=media, fields='id').execute()\n",
    "    gfiles += [gfile]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "# grab camera hardware and monitor\n",
    "#####################################################\n",
    "snapshot = np.empty((1024, 1280, 3), dtype=np.uint8)\n",
    "background = None\n",
    "box = (0, 1280, 350, 850)\n",
    "gg = 0\n",
    "state = 0  # 0 - no motion, 1 - initial motion, >1 - subsequent motion\n",
    "prev_center, prev_timestamp = np.array([0,0]), 0.0\n",
    "prev_cutout = np.zeros_like(snapshot, dtype=np.uint8)\n",
    "\n",
    "\n",
    "#fig, ax = plt.subplots(figsize=(14, 14))\n",
    "#ax.imshow(background)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/picamera/encoders.py:521: PiCameraAlphaStripping: using alpha-stripping to convert to non-alpha format; you may find the equivalent alpha format faster\n",
      "  \"using alpha-stripping to convert to non-alpha \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "motion detected in image 0...distance of 308 in 0.5 seconds\n",
      "motion detected in image 1...distance of 307 in 0.6 seconds\n",
      "motion detected in image 2...distance of 341 in 0.6 seconds\n",
      "motion detected in image 3...distance of 153 in 0.5 seconds\n",
      "motion detected in image 4...distance of 2 in 0.5 seconds\n",
      "motion detected in image 5...distance of 2 in 0.6 seconds\n",
      "motion detected in image 6...distance of 1 in 0.6 seconds\n",
      "motion detected in image 7...distance of 0 in 0.7 seconds\n",
      "motion detected in image 8...distance of 1 in 0.6 seconds\n",
      "motion detected in image 9...distance of 0 in 0.6 seconds\n",
      "motion detected in image 10...distance of 0 in 0.6 seconds\n",
      "motion detected in image 11...distance of 0 in 0.6 seconds\n",
      "motion detected in image 12...distance of 0 in 0.6 seconds\n",
      "motion detected in image 13...distance of 1 in 0.7 seconds\n",
      "motion detected in image 14...distance of 1 in 0.6 seconds\n",
      "motion detected in image 15...distance of 1 in 0.6 seconds\n",
      "motion detected in image 16...distance of 1 in 0.6 seconds\n",
      "motion detected in image 17...distance of 2 in 0.6 seconds\n",
      "motion detected in image 18...distance of 1 in 0.6 seconds\n",
      "motion detected in image 19...distance of 0 in 0.6 seconds\n",
      "motion detected in image 20...distance of 1 in 0.6 seconds\n",
      "motion detected in image 21...distance of 1 in 0.5 seconds\n",
      "motion detected in image 22...distance of 1 in 0.7 seconds\n",
      "motion detected in image 23...distance of 1 in 0.6 seconds\n",
      "motion detected in image 24...distance of 1 in 0.6 seconds\n",
      "motion detected in image 25...distance of 1 in 0.6 seconds\n",
      "motion detected in image 26...distance of 1 in 0.6 seconds\n",
      "motion detected in image 27...distance of 0 in 0.6 seconds\n",
      "motion detected in image 28...distance of 21 in 0.6 seconds\n",
      "motion detected in image 29...distance of 49 in 0.6 seconds\n",
      "motion detected in image 30...distance of 41 in 0.6 seconds\n",
      "motion detected in image 31...distance of 43 in 0.5 seconds\n",
      "motion detected in image 32...distance of 7 in 0.6 seconds\n",
      "motion detected in image 33...distance of 7 in 0.5 seconds\n",
      "motion detected in image 34...distance of 0 in 0.6 seconds\n",
      "motion detected in image 35...distance of 1 in 0.6 seconds\n",
      "motion detected in image 36...distance of 1 in 0.6 seconds\n",
      "motion detected in image 37...distance of 0 in 0.5 seconds\n",
      "motion detected in image 38...distance of 1 in 0.6 seconds\n",
      "motion detected in image 39...distance of 2 in 0.6 seconds\n",
      "motion detected in image 40...distance of 0 in 0.6 seconds\n",
      "motion detected in image 41...distance of 1 in 0.6 seconds\n",
      "motion detected in image 42...distance of 0 in 0.6 seconds\n",
      "motion detected in image 43...distance of 3 in 0.6 seconds\n",
      "motion detected in image 44...distance of 2 in 0.6 seconds\n",
      "motion detected in image 45...distance of 2 in 0.6 seconds\n",
      "motion detected in image 46...distance of 1 in 0.6 seconds\n",
      "motion detected in image 47...distance of 1 in 0.7 seconds\n",
      "motion detected in image 48...distance of 0 in 0.6 seconds\n"
     ]
    }
   ],
   "source": [
    "with PiCamera() as camera:\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        while True:  #for ii in range(num_pictures):\n",
    "            #print('processing image ' + str(ii+1), end='\\r')\n",
    "            time.sleep(0.25)\n",
    "            camera.capture(snapshot, format='bgr', use_video_port=True, resize=(1280, 1024))\n",
    "\n",
    "            cutout = snapshot[box[2]:box[3], box[0]:box[1]]\n",
    "            frame = cv2.cvtColor(cutout, cv2.COLOR_BGR2GRAY)\n",
    "            frame = cv2.GaussianBlur(frame, (21, 21), 0)\n",
    "\n",
    "            if background is None:\n",
    "                background = frame.copy().astype('float')\n",
    "            \n",
    "            # compute the difference between the current frame and running average\n",
    "            frameDelta = cv2.absdiff(frame, cv2.convertScaleAbs(background))\n",
    "            \n",
    "            # threshold the delta image, dilate the thresholded image to fill in holes,\n",
    "            # then find contours on thresholded image\n",
    "            thresh = cv2.threshold(frameDelta, 10, 255, cv2.THRESH_BINARY)[1]\n",
    "            thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "            cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            cnts = imutils.grab_contours(cnts)\n",
    "            \n",
    "            # look for large contour areas\n",
    "            motion = False\n",
    "            for cc in cnts:\n",
    "                if cv2.contourArea(cc) < 300:\n",
    "                    continue\n",
    "                \n",
    "                # can't deal with multiple things moving at once\n",
    "                if motion == True:\n",
    "                    motion = False\n",
    "                    break\n",
    "                \n",
    "                # compute the bounding box for the contour, draw it on the frame, and update the text\n",
    "                motion = True\n",
    "                (xx, yy, ww, hh) = cv2.boundingRect(cc)\n",
    "                center = np.array([xx + ww//2, yy + hh//2])\n",
    "                timestamp = time.time()\n",
    "                rc = cv2.rectangle(cutout, (xx, yy), (xx + ww, yy + hh), (0, 255, 0), 2)\n",
    "                #snapshot[box[2]:box[3], box[0]:box[1]] = cutout\n",
    "            \n",
    "            # last frame also had motion\n",
    "            if motion and (state == 1):\n",
    "                distance = np.sqrt(np.sum( np.square(center - prev_center) ))\n",
    "                timedelta = timestamp - prev_timestamp\n",
    "                two_frame = np.concatenate((prev_cutout, cutout), axis=0)\n",
    "                print('motion detected in image ' + str(gg) + '...distance of {:1.0f} in {:3.1f} seconds'.format(distance, timedelta), end='\\r')\n",
    "                rc = cv2.imwrite('pictures/motion' + str(gg) + '.jpg', two_frame)\n",
    "                #media = MediaFileUpload('pictures/motion' + str(gg) + '.jpg', mimetype='image/jpg')\n",
    "                #gfile = drive.files().update(fileId=gfiles[gg], media_body=media).execute()\n",
    "                gg = (gg + 1) % num_pictures\n",
    "            \n",
    "            else:\n",
    "                two_frame = cutout\n",
    "                \n",
    "            #rc = cv2.imwrite('pictures/motion' + str(gg) + '.jpg', two_frame)\n",
    "            #gg = (gg + 1) % num_pictures\n",
    "            \n",
    "            if motion:\n",
    "                state = 1\n",
    "                prev_center = center\n",
    "                prev_timestamp = timestamp\n",
    "                prev_cutout = np.array(cutout)\n",
    "            \n",
    "            # no motion\n",
    "            else:\n",
    "                state = 0\n",
    "                #rc = cv2.accumulateWeighted(frame, background, 0.5)\n",
    "                background = frame.copy().astype('float')\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploading 50\r"
     ]
    }
   ],
   "source": [
    "for ii in range(num_pictures):\n",
    "    print('uploading ' + str(ii+1), end='\\r')\n",
    "    if os.path.exists('pictures/motion' + str(ii) + '.jpg'):\n",
    "        media = MediaFileUpload('pictures/motion' + str(ii) + '.jpg', mimetype='image/jpg')\n",
    "        gfile = drive.files().update(fileId=gfiles[ii], media_body=media).execute()\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
